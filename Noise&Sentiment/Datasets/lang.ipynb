{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becoming-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, pandas as pd,numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-example",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stainless-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in c:\\users\\jahli\\appdata\\roaming\\python\\python37\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.26.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.55.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.8)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jahli\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata>=0.20->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.12)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jahli\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "configured-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fallen-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.tokenize import word_tokenize\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "original-gospel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rev = pd.read_csv(\"C:/Users/jahli/Documents/projects/Noise&Sentiment/datasets/hotel_updatedfin3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "seventh-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>date</th>\n",
       "      <th>date1</th>\n",
       "      <th>date2</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>address</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>weather</th>\n",
       "      <th>w_value</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TSUN</th>\n",
       "      <th>num_id</th>\n",
       "      <th>loc_codes1</th>\n",
       "      <th>stationb</th>\n",
       "      <th>b_coord</th>\n",
       "      <th>backup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVwc252WIN2L1WUfpqLP</td>\n",
       "      <td>2016-10-30 21:42:42</td>\n",
       "      <td>2013-11-14</td>\n",
       "      <td>2013-11-14</td>\n",
       "      <td>2013</td>\n",
       "      <td>2018-09-10 21:06:27</td>\n",
       "      <td>5921 Valencia Cir</td>\n",
       "      <td>Hotels,Hotels and motels,Hotel and motel reser...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Rancho Santa Fe</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "      <td>available</td>\n",
       "      <td>GHCND:US1CASD0001</td>\n",
       "      <td>-117.1316 33.1472</td>\n",
       "      <td>GHCND:US1CASD0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVwc252WIN2L1WUfpqLP</td>\n",
       "      <td>2016-10-30 21:42:42</td>\n",
       "      <td>2014-07-06</td>\n",
       "      <td>2014-07-06</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-09-10 21:06:27</td>\n",
       "      <td>5921 Valencia Cir</td>\n",
       "      <td>Hotels,Hotels and motels,Hotel and motel reser...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Rancho Santa Fe</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>2</td>\n",
       "      <td>available</td>\n",
       "      <td>GHCND:US1CASD0001</td>\n",
       "      <td>-117.1316 33.1472</td>\n",
       "      <td>GHCND:US1CASD0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVwc252WIN2L1WUfpqLP</td>\n",
       "      <td>2016-10-30 21:42:42</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>2018-09-10 21:06:27</td>\n",
       "      <td>5921 Valencia Cir</td>\n",
       "      <td>Hotels,Hotels and motels,Hotel and motel reser...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Rancho Santa Fe</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>3</td>\n",
       "      <td>available</td>\n",
       "      <td>GHCND:US1CASD0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GHCND:US1CASD0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVwdOclqIN2L1WUfti38</td>\n",
       "      <td>2015-11-28 19:19:35</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>2016</td>\n",
       "      <td>2018-09-10 21:06:16</td>\n",
       "      <td>7520 Teague Rd</td>\n",
       "      <td>Hotels,Hotels and motels,Travel agencies and b...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Hanover</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>4</td>\n",
       "      <td>H0otG707</td>\n",
       "      <td>GHCND:US1DCDC0010</td>\n",
       "      <td>-77.02445991 38.97729754</td>\n",
       "      <td>GHCND:US1DCDC0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVwdOclqIN2L1WUfti38</td>\n",
       "      <td>2015-11-28 19:19:35</td>\n",
       "      <td>2016-07-09</td>\n",
       "      <td>2016-07-09</td>\n",
       "      <td>2016</td>\n",
       "      <td>2018-09-10 21:06:16</td>\n",
       "      <td>7520 Teague Rd</td>\n",
       "      <td>Hotels,Hotels and motels,Travel agencies and b...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Hanover</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>5</td>\n",
       "      <td>H0otG707</td>\n",
       "      <td>GHCND:US1DCDC0010</td>\n",
       "      <td>-77.02445991 38.97729754</td>\n",
       "      <td>GHCND:US1DCDC0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>AVwd4TMv_7pvs4fz-Ers</td>\n",
       "      <td>2016-03-24 11:44:15</td>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>2016</td>\n",
       "      <td>2018-01-01 00:00:46</td>\n",
       "      <td>215 S Pacific St</td>\n",
       "      <td>Hotel,Hotels,Lodging,Motels</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Rockaway Beach</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>9996</td>\n",
       "      <td>hCe5Eags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>AVwdRp4DIN2L1WUfuGZZ</td>\n",
       "      <td>2015-10-26 23:03:02</td>\n",
       "      <td>2015-12-11</td>\n",
       "      <td>2015-12-11</td>\n",
       "      <td>2015</td>\n",
       "      <td>2018-01-01 00:00:44</td>\n",
       "      <td>669 Route 6a</td>\n",
       "      <td>Hotel,Hotels</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>East Sandwich</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>9997</td>\n",
       "      <td>e44TkdqV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COOP:195160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>AVwd1TbkByjofQCxs6FH</td>\n",
       "      <td>2016-06-11 03:12:23</td>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-01-01 00:00:44</td>\n",
       "      <td>702 W Appleway Ave</td>\n",
       "      <td>Hotel,Hotel, Motel, and Building,Hotels,Lodgin...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Coeur d'Alene</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>9998</td>\n",
       "      <td>BpxJJPqL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GHCND:US1IDBR0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>AVwdHbizIN2L1WUfsXto</td>\n",
       "      <td>2016-12-13 03:44:36</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>2016</td>\n",
       "      <td>2018-01-01 00:00:43</td>\n",
       "      <td>2295 N Highland Ave</td>\n",
       "      <td>Hotel,Hotels Motels,Budget Hotels,Hotels &amp; Motels</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>9999</td>\n",
       "      <td>8LPQl9Iq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GHCND:US1TNGB0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>AVwddMfdIN2L1WUfwAue</td>\n",
       "      <td>2016-06-22 19:07:21</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>2013</td>\n",
       "      <td>2018-01-01 00:00:43</td>\n",
       "      <td>3811 Minnesota Dr</td>\n",
       "      <td>Hotel,Motels,Lodging,Hotels,Hotels and Motels</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>10000</td>\n",
       "      <td>o4P4WEme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id            dateAdded        date       date1  \\\n",
       "0     AVwc252WIN2L1WUfpqLP  2016-10-30 21:42:42  2013-11-14  2013-11-14   \n",
       "1     AVwc252WIN2L1WUfpqLP  2016-10-30 21:42:42  2014-07-06  2014-07-06   \n",
       "2     AVwc252WIN2L1WUfpqLP  2016-10-30 21:42:42  2015-01-02  2015-01-02   \n",
       "3     AVwdOclqIN2L1WUfti38  2015-11-28 19:19:35  2016-05-15  2016-05-15   \n",
       "4     AVwdOclqIN2L1WUfti38  2015-11-28 19:19:35  2016-07-09  2016-07-09   \n",
       "...                    ...                  ...         ...         ...   \n",
       "9995  AVwd4TMv_7pvs4fz-Ers  2016-03-24 11:44:15  2016-03-13  2016-03-13   \n",
       "9996  AVwdRp4DIN2L1WUfuGZZ  2015-10-26 23:03:02  2015-12-11  2015-12-11   \n",
       "9997  AVwd1TbkByjofQCxs6FH  2016-06-11 03:12:23  2017-11-17  2017-11-17   \n",
       "9998  AVwdHbizIN2L1WUfsXto  2016-12-13 03:44:36  2016-06-09  2016-06-09   \n",
       "9999  AVwddMfdIN2L1WUfwAue  2016-06-22 19:07:21  2013-09-03  2013-09-03   \n",
       "\n",
       "      date2          dateUpdated              address  \\\n",
       "0      2013  2018-09-10 21:06:27    5921 Valencia Cir   \n",
       "1      2014  2018-09-10 21:06:27    5921 Valencia Cir   \n",
       "2      2015  2018-09-10 21:06:27    5921 Valencia Cir   \n",
       "3      2016  2018-09-10 21:06:16       7520 Teague Rd   \n",
       "4      2016  2018-09-10 21:06:16       7520 Teague Rd   \n",
       "...     ...                  ...                  ...   \n",
       "9995   2016  2018-01-01 00:00:46     215 S Pacific St   \n",
       "9996   2015  2018-01-01 00:00:44         669 Route 6a   \n",
       "9997   2017  2018-01-01 00:00:44   702 W Appleway Ave   \n",
       "9998   2016  2018-01-01 00:00:43  2295 N Highland Ave   \n",
       "9999   2013  2018-01-01 00:00:43    3811 Minnesota Dr   \n",
       "\n",
       "                                             categories  \\\n",
       "0     Hotels,Hotels and motels,Hotel and motel reser...   \n",
       "1     Hotels,Hotels and motels,Hotel and motel reser...   \n",
       "2     Hotels,Hotels and motels,Hotel and motel reser...   \n",
       "3     Hotels,Hotels and motels,Travel agencies and b...   \n",
       "4     Hotels,Hotels and motels,Travel agencies and b...   \n",
       "...                                                 ...   \n",
       "9995                        Hotel,Hotels,Lodging,Motels   \n",
       "9996                                       Hotel,Hotels   \n",
       "9997  Hotel,Hotel, Motel, and Building,Hotels,Lodgin...   \n",
       "9998  Hotel,Hotels Motels,Budget Hotels,Hotels & Motels   \n",
       "9999      Hotel,Motels,Lodging,Hotels,Hotels and Motels   \n",
       "\n",
       "                  primaryCategories             city  ... weather w_value  \\\n",
       "0     Accommodation & Food Services  Rancho Santa Fe  ...     NaN       0   \n",
       "1     Accommodation & Food Services  Rancho Santa Fe  ...     NaN       0   \n",
       "2     Accommodation & Food Services  Rancho Santa Fe  ...     NaN       0   \n",
       "3     Accommodation & Food Services          Hanover  ...     NaN       0   \n",
       "4     Accommodation & Food Services          Hanover  ...     NaN       0   \n",
       "...                             ...              ...  ...     ...     ...   \n",
       "9995  Accommodation & Food Services   Rockaway Beach  ...     NaN       0   \n",
       "9996  Accommodation & Food Services    East Sandwich  ...     NaN       0   \n",
       "9997  Accommodation & Food Services    Coeur d'Alene  ...     NaN       0   \n",
       "9998  Accommodation & Food Services          Jackson  ...     NaN       0   \n",
       "9999  Accommodation & Food Services        Anchorage  ...     NaN       0   \n",
       "\n",
       "       SNOW   PRCP   TSUN num_id loc_codes1           stationb  \\\n",
       "0       NaN      0  EMPTY      1  available  GHCND:US1CASD0001   \n",
       "1         0      0  EMPTY      2  available  GHCND:US1CASD0001   \n",
       "2         0      0  EMPTY      3  available  GHCND:US1CASD0001   \n",
       "3       NaN     43  EMPTY      4   H0otG707  GHCND:US1DCDC0010   \n",
       "4       NaN     28  EMPTY      5   H0otG707  GHCND:US1DCDC0010   \n",
       "...     ...    ...    ...    ...        ...                ...   \n",
       "9995  EMPTY  EMPTY  EMPTY   9996   hCe5Eags                NaN   \n",
       "9996    NaN     23  EMPTY   9997   e44TkdqV                NaN   \n",
       "9997  EMPTY  EMPTY  EMPTY   9998   BpxJJPqL                NaN   \n",
       "9998      0      0  EMPTY   9999   8LPQl9Iq                NaN   \n",
       "9999  EMPTY  EMPTY  EMPTY  10000   o4P4WEme                NaN   \n",
       "\n",
       "                       b_coord             backup  \n",
       "0            -117.1316 33.1472  GHCND:US1CASD0006  \n",
       "1            -117.1316 33.1472  GHCND:US1CASD0006  \n",
       "2                          NaN  GHCND:US1CASD0006  \n",
       "3     -77.02445991 38.97729754  GHCND:US1DCDC0019  \n",
       "4     -77.02445991 38.97729754  GHCND:US1DCDC0019  \n",
       "...                        ...                ...  \n",
       "9995                       NaN                NaN  \n",
       "9996                       NaN        COOP:195160  \n",
       "9997                       NaN  GHCND:US1IDBR0025  \n",
       "9998                       NaN  GHCND:US1TNGB0013  \n",
       "9999                       NaN                NaN  \n",
       "\n",
       "[10000 rows x 42 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "iraqi-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "straight-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    post = pos_tag(tokens)\n",
    "    #doc = nlp(tokens)\n",
    "    #post = [(token.text, token.pos_) for token in doc]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    \n",
    "\n",
    "    # Join lemmatized tokens back into a string\n",
    "    preprocessed_text = \" \".join(lemmatized_tokens)\n",
    "\n",
    "    return preprocessed_text, post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "general-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_lst = nlp.pipe_labels['tagger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "configured-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\jahli/nltk_data'\n    - 'C:\\\\Users\\\\jahli\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\jahli\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\jahli\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\jahli\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-09e02d0186b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleaned_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Happy birthday Noelle! You are the most beautiful cat!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-5f4a94555a2a>\u001b[0m in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m#doc = nlp(tokens)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#post = [(token.text, token.pos_) for token in doc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \"\"\"\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             AP_MODEL_LOC = \"file:\" + str(\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"taggers/averaged_perceptron_tagger/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             )\n\u001b[0;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\jahli/nltk_data'\n    - 'C:\\\\Users\\\\jahli\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\jahli\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\jahli\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\jahli\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = preprocess_text(\"Happy birthday Noelle! You are the most beautiful cat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "brief-detail",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got tuple)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-dd3e68d63318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    976\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;31m#call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m         \"\"\"\n\u001b[1;32m--> 978\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1058\u001b[0m                 \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m             )\n\u001b[1;32m-> 1060\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m     def update(\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got tuple)"
     ]
    }
   ],
   "source": [
    "nlp(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "trained-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "    # Join lemmatized tokens back into a string\n",
    "    preprocessed_text = \" \".join(lemmatized_tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "supposed-broadcast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample text sentiment analysis .\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a sample text for sentiment analysis.\"\n",
    "preprocessed_text = preprocess_text(text)\n",
    "print(preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "rotary-patrol",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "[E046] Can't retrieve unregistered extension attribute 'sentiment'. Did you forget to call the `set_extension` method?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-8846a034579a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sentiment:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokens\\underscore.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extensions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE046\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extensions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: [E046] Can't retrieve unregistered extension attribute 'sentiment'. Did you forget to call the `set_extension` method?"
     ]
    }
   ],
   "source": [
    "doc = nlp(preprocessed_text)\n",
    "sentiment = doc._.sentiment\n",
    "print(\"Sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "particular-chess",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-684d20d1a6ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"POS Tags (spaCy):\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "doc = nlp(cleaned_text)\n",
    "print(\"POS Tags (spaCy):\", [(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "regular-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-484a4b568b66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"reviews.text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rev' is not defined"
     ]
    }
   ],
   "source": [
    "preprocess_text(rev[\"reviews.text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "enclosed-england",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-99cb74c94aec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Happy birthday Noelle! You are the most beautiful cat!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-e5b50fb26266>\u001b[0m in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Tokenize text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mpost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    976\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;31m#call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m         \"\"\"\n\u001b[1;32m--> 978\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1058\u001b[0m                 \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m             )\n\u001b[1;32m-> 1060\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m     def update(\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got list)"
     ]
    }
   ],
   "source": [
    "preprocess_text(\"Happy birthday Noelle! You are the most beautiful cat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
